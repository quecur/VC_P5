{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea:\n",
    "Tras mostrar opciones para la detección y extracción de información de caras humanas con deepface, la tarea a entregar consiste en proponer un escenario de aplicación y desarrollar un prototipo de temática libreque provoque reacciones a partir de la información extraida del rostro. Los detectores proporcionan información del rostro, y de sus elementos faciales. Ideas inmediatas pueden ser filtros, aunque no hay limitaciones en este sentido. La entrega debe venir acompañada de un gif animado o vídeo de un máximo de 30 segundos con momentos seleccionados de la propuesta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cquevedo\\AppData\\Local\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Cargar la imagen del sombrero y el parche\n",
    "img = cv2.imread('sombrero.jpg')\n",
    "img2 = cv2.imread('parche.jpg')\n",
    "\n",
    "# Convertir las imágenes a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar un umbral para crear imágenes binarias\n",
    "_, umbral = cv2.threshold(gray, 245, 255, cv2.THRESH_BINARY_INV)\n",
    "_, umbral2 = cv2.threshold(gray2, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Encontrar los contornos en la imagen binaria\n",
    "contornos, _ = cv2.findContours(umbral, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contornos2, _ = cv2.findContours(umbral2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Crear una máscara vacía\n",
    "mascara = np.zeros_like(img)\n",
    "mascara2 = np.zeros_like(img2)\n",
    "\n",
    "# Rellenar las máscaras con el contorno del objeto (sombrero y parche)\n",
    "cv2.drawContours(mascara, contornos, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "cv2.drawContours(mascara2, contornos2, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "# Extraer los objetos (sombrero y parche) de las imágenes originales utilizando las máscaras\n",
    "objeto_extraido = cv2.bitwise_and(img, mascara)\n",
    "objeto_extraido2 = cv2.bitwise_and(img2, mascara2)\n",
    "\n",
    "# Inicializar MediaPipe Face Detection para detectar los puntos de la cara\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.2)\n",
    "\n",
    "# Inicializar MediaPipe Face Mesh para detectar los puntos de la cara con mayor precision\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.2)\n",
    "\n",
    "def eye_aspect_ratio(coordinates):\n",
    "     d_A = np.linalg.norm(np.array(coordinates[1]) - np.array(coordinates[5]))\n",
    "     d_B = np.linalg.norm(np.array(coordinates[2]) - np.array(coordinates[4]))\n",
    "     d_C = np.linalg.norm(np.array(coordinates[0]) - np.array(coordinates[3]))\n",
    "     return (d_A + d_B) / (2 * d_C)\n",
    "\n",
    "def drawing_output(frame, blink_counter):\n",
    "     aux_image = np.zeros(frame.shape, np.uint8)\n",
    "     output = cv2.addWeighted(frame, 1, aux_image, 0.7, 1)\n",
    "     cv2.rectangle(output, (0, 0), (210, 50), (0, 0, 0), -1)\n",
    "     cv2.rectangle(output, (212, 0), (265, 50), (0, 0, 0),-1)\n",
    "     cv2.putText(output, \"Num. Parpadeos:\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "     cv2.putText(output, \"{}\".format(blink_counter), (220, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "     return output\n",
    "\n",
    "\n",
    "index_left_eye = [33, 160, 158, 133, 153, 144]\n",
    "index_right_eye = [362, 385, 387, 263, 373, 380]\n",
    "EAR_THRESH = 0.26\n",
    "NUM_FRAMES = 2\n",
    "aux_counter = 0\n",
    "blink_counter = 0\n",
    "pts_ear = deque(maxlen=64)\n",
    "i = 0\n",
    "\n",
    "# Iniciar la captura de video\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    #Coodenadas ojos izquierdo y derecho\n",
    "    coordinates_left_eye = []\n",
    "    coordinates_right_eye = []\n",
    "\n",
    "    # Convertir el fotograma a RGB para MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Contador de parpadeos\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    if results.multi_face_landmarks is not None:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for index in index_left_eye:\n",
    "                x = int(face_landmarks.landmark[index].x * width)\n",
    "                y = int(face_landmarks.landmark[index].y * height)\n",
    "                coordinates_left_eye.append([x, y])\n",
    "            for index in index_right_eye:\n",
    "                x = int(face_landmarks.landmark[index].x * width)\n",
    "                y = int(face_landmarks.landmark[index].y * height)\n",
    "                coordinates_right_eye.append([x, y])\n",
    "        ear_left_eye = eye_aspect_ratio(coordinates_left_eye)\n",
    "        ear_right_eye = eye_aspect_ratio(coordinates_right_eye)\n",
    "        ear = (ear_left_eye + ear_right_eye)/2\n",
    "        # Ojos cerrados\n",
    "        if ear < EAR_THRESH:\n",
    "            aux_counter += 1\n",
    "        else:\n",
    "            if aux_counter >= NUM_FRAMES:\n",
    "                aux_counter = 0\n",
    "                blink_counter += 1                \n",
    "        frame = drawing_output(frame, blink_counter)\n",
    "\n",
    "        if(blink_counter%2!=0):\n",
    "\n",
    "            results = face_detection.process(frame_rgb)\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    # Obtener la caja delimitadora (bounding box) de la cara\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = frame.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    # Establecer un factor de escala para aumentar el tamaño del sombrero\n",
    "                    escala_sombrero = 1.3  # Aumentar el tamaño del sombrero en un 30% (ajustar este valor según sea necesario)\n",
    "                    # Redimensionar la imagen del sombrero para que se ajuste a la cara con un tamaño aumentado\n",
    "                    overlay = cv2.resize(objeto_extraido, (int(w * escala_sombrero), int(h * escala_sombrero)))\n",
    "                    # Determinar la nueva posición para colocar el sombrero centrado encima de la cabeza\n",
    "                    y_offset = int(h * 0)  # Coloca el sombrero por encima de la cabeza\n",
    "                    x_offset = int(w * 0.5)  # Centrar el sombrero sobre el ancho de la cara\n",
    "                    # Redefinir las coordenadas para el sombrero centrado sobre la cara\n",
    "                    new_x = x + (w // 2) - (overlay.shape[1] // 2)  # Centrado horizontalmente\n",
    "                    new_y = y - overlay.shape[0] + y_offset  # Colocado por encima de la cabeza\n",
    "                    # Asegurarse de que el sombrero no se mueva fuera de los límites de la imagen\n",
    "                    new_x = max(new_x, 0)\n",
    "                    new_y = max(new_y, 0)\n",
    "                    # Obtener la región del fotograma donde se colocará el sombrero\n",
    "                    n_frame = frame[new_y:new_y+overlay.shape[0], new_x:new_x+overlay.shape[1]]   \n",
    "                    # Convertir la imagen del sombrero a escala de grises para obtener la máscara\n",
    "                    gray_overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "                    # Aplicar un umbral a la imagen en escala de grises para generar la máscara\n",
    "                    _, mask = cv2.threshold(gray_overlay, 1, 255, cv2.THRESH_BINARY)\n",
    "                    # Invertir la máscara\n",
    "                    mask_inv = cv2.bitwise_not(mask)  \n",
    "                    # Extraer la parte de la cara (fondo) que no tiene el sombrero\n",
    "                    bg_frame = cv2.bitwise_and(n_frame, n_frame, mask=mask_inv)\n",
    "                    # Extraer la parte del sombrero donde se va a colocar\n",
    "                    fg_overlay = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "                    # Combinar el fondo de la cara y el sombrero en la misma región\n",
    "                    result = cv2.add(bg_frame, fg_overlay)\n",
    "                    # Superponer el resultado en el fotograma original\n",
    "                    frame[new_y:new_y+overlay.shape[0], new_x:new_x+overlay.shape[1]] = result\n",
    "\n",
    "            results = face_mesh.process(frame_rgb)\n",
    "            if results.multi_face_landmarks:\n",
    "                for landmarks in results.multi_face_landmarks:\n",
    "                    # Obtener las coordenadas del ojo derecho (punto 263 en MediaPipe)\n",
    "                    ih, iw, _ = frame.shape\n",
    "                    right_eye = landmarks.landmark[263]  # Ojo derecho (punto 263)\n",
    "                    # Convertir las coordenadas normalizadas a píxeles\n",
    "                    right_eye_x, right_eye_y = int(right_eye.x * iw), int(right_eye.y * ih)\n",
    "                    # Redimensionar el parche para que encaje sobre el ojo derecho\n",
    "                    overlay = cv2.resize(objeto_extraido2, (80, 80))  # Tamaño del parche\n",
    "                    h, w, _ = overlay.shape\n",
    "                    # Determinar la posición para colocar el parche (encima del ojo derecho)\n",
    "                    y_offset = int(h * 0.5)  # Coloca el parche justo sobre el ojo\n",
    "                    y = max(right_eye_y - y_offset, 0)  # Asegurarse de que no se mueva fuera de los límites de la imagen\n",
    "                    x = right_eye_x - w // 2 - 10  # Centrar el parche sobre el ojo derecho\n",
    "                    # Extraer la región de la cara (en este caso, sobre el ojo derecho)\n",
    "                    n_frame = frame[y:y+h, x:x+w]\n",
    "                    # Convertir la imagen del parche a escala de grises para obtener la máscara\n",
    "                    gray_overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "                    # Aplicar un umbral a la imagen en escala de grises para generar la máscara\n",
    "                    _, mask = cv2.threshold(gray_overlay, 1, 255, cv2.THRESH_BINARY)\n",
    "                    # Invertir la máscara\n",
    "                    mask_inv = cv2.bitwise_not(mask)\n",
    "                    # Extraer la parte de la cara (fondo) que no tiene el parche\n",
    "                    bg_frame = cv2.bitwise_and(n_frame, n_frame, mask=mask_inv)\n",
    "                    # Extraer la parte del parche donde se va a colocar\n",
    "                    fg_overlay = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "                    # Combinar el fondo de la cara y el parche en la misma región\n",
    "                    result = cv2.add(bg_frame, fg_overlay)\n",
    "                    # Superponer el resultado en el fotograma original\n",
    "                    frame[y:y+h, x:x+w] = result\n",
    "\n",
    "    # Mostrar el fotograma con el parche superpuesto\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Detener la ejecución con la tecla ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la captura de video y cerrar las ventanas\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
